# Movies - ETL


## Project Overview
This project will look closely at the data pipeline process caled ETL or Extract-Transfer-Load. This is a core concept in data engineering and is often used to move data around while ensuring that the data is consistent and maintains it's integretity. This process allows for a high degree of trust and reliability when performing analysis against the data. Further, a well designed ETL pipeline strives to automate as much of the data wrangling process as possible while leaving more time for analysis and modeling. We can also create data stores using the ETL process that perform more efficiently while  blending data from multiple sources. In this implementation, Python and Pandas will be used to perform the data wrangling while PostgreSQL will be used to store the finished data.

- Deliverables:
  1. Design an ETL function to read three different data files
  2. Extract and Transform Wikipedia data
  3. Extract and Transform Kaggle data
  4. Create the movie data and store in PostgreSQL

## Resources
- Database Client: pgAdmin v5.2
- Database Server: PostgreSQL v13
- Data Source(s) : wikipedia-movies.json, ratings.csv, movies_metadata.csv
- Software: Python 3.7.10, Visual Studio Code 1.56.2, Jupyter Notebook Server 6.3.0

## Results

### Analysis of Deliverable 1



### Analysis of Deliverable 2




## Overall Summary



## Recommendations: